# dbt-airflow
A Python package that creates fine-grained dbt tasks on Apache Airflow.

## How does it work
The library essentially builds on top of the metadata generated by `dbt-core` and are stored in 
the `target/manifest.json` file in your dbt profile directory.  

---

# Installation

The package is available on PyPI and can be installed through `pip`:
```bash
pip install dbt-airflow
```

`dbt` needs to connect to your target environment (database, warehouse etc.) and in order to do so, it makes use of 
different adapters, each dedicated to a different technology (such as Postgres or BigQuery). Therefore, before running
`dbt-airflow` you also need to ensure that the required adapter(s) are installed in your environment. 

For the full list of available adapters please refer to the official 
[dbt documentation](https://docs.getdbt.com/docs/available-adapters). 

---

# Usage


---

# Contributing
If you wish to contribute to this project, you first need to setup a proper development environment where
you will be able to install all the dependencies required in order to run and test new functionality or bug fixes. 

To do so, you first need to create and then activate a virtual environment:
```bash
$ python3 -m venv ~/dbt-airflow-venv
$ source ~/dbt-airflow-venv/bin/activate
```

Now once you have activated your environment, you'll then need to install `dbt-airflow` in **editable mode**. 
When this mode is activated, the package will be linked to the specified directory (which should be the directory 
containing the package under development) such that any changes made in the package will be reflected directly 
in your local environment. 

You can do so using the `-e` (or `--editable`) flag when instlling the package through `pip`:
```bash
pip install -e .
```

